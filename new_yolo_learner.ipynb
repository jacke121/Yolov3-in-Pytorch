{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:03.085508Z",
     "start_time": "2018-07-01T02:18:03.062793Z"
    }
   },
   "outputs": [],
   "source": [
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:03.846618Z",
     "start_time": "2018-07-01T02:18:03.086730Z"
    }
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms as trans\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from models.Yolo_model import Yolo_model, build_targets, yolo_loss\n",
    "import numpy as np\n",
    "# np.seterr(all='raise')\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "# import torch.nn.functional as F\n",
    "from utils.vis_utils import *\n",
    "from utils.box_utils import *\n",
    "from utils.dataset_tools import *\n",
    "from utils.utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "# s\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:15.457755Z",
     "start_time": "2018-07-01T02:18:03.847863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.44s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "conf = edict()\n",
    "\n",
    "conf.coco_anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],\n",
    "                     [59, 119], [116, 90], [156, 198], [373, 326]]\n",
    "conf.train_path = Path('/home/f/nvme/coco2017/train2017/')\n",
    "conf.train_anno_path = Path(\n",
    "    '/home/f/nvme/coco2017/annotations/instances_train2017.json')\n",
    "conf.val_path = Path('/home/f/nvme/coco2017/val2017/')\n",
    "conf.val_anno_path = Path(\n",
    "    '/home/f/nvme/coco2017/annotations/instances_val2017.json')\n",
    "conf.log_path = Path('/home/f/learning/yolo/log')\n",
    "conf.model_path = Path('/home/f/learning/yolo/model')\n",
    "conf.save_path = Path('/home/f/learning/yolo/save')\n",
    "conf.ids_path = 'data/ids.npy'\n",
    "\n",
    "conf.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "maps,correct_id_2_class = get_id_maps(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:18.380670Z",
     "start_time": "2018-07-01T02:18:15.459417Z"
    }
   },
   "outputs": [],
   "source": [
    "conf.num_anchors = 3\n",
    "conf.batch_size = 16\n",
    "conf.input_size = 416\n",
    "conf.scales = [32,16,8]\n",
    "\n",
    "conf.running_norm = 0.\n",
    "# conf.gdclip = 3000.\n",
    "conf.num_workers = 8\n",
    "conf.batch_size = 16\n",
    "conf.gdclip = None\n",
    "conf.coord_scale = 2.\n",
    "conf.noobject_scale = 0.5\n",
    "conf.object_scale = 5\n",
    "conf.class_scale = 5.\n",
    "conf.ignore_thresh = 0.5\n",
    "conf.evaluate_iou_threshold = 0.5\n",
    "conf.predict_confidence_threshold = 0.5\n",
    "conf.pred_nms_iou_threshold = 0.5\n",
    "conf.object_only = True\n",
    "conf.warm_up_img_num = 12800\n",
    "\n",
    "model = Yolo_model(conf)\n",
    "model.to(conf.device)\n",
    "conf.mean = model.res50_pyramid.model.mean\n",
    "conf.std = model.res50_pyramid.model.std\n",
    "\n",
    "conf.mse_loss = nn.MSELoss(size_average=False)\n",
    "conf.bce_loss = nn.BCEWithLogitsLoss(size_average=False)\n",
    "\n",
    "conf.board_loss_every = 5\n",
    "conf.evaluate_every = 5\n",
    "conf.board_pred_image_every = 5\n",
    "# conf.board_loss_every = len(train_loader) // 100\n",
    "# conf.evaluate_every = len(train_loader) // 10\n",
    "# conf.board_pred_image_every = len(train_loader) // 2\n",
    "# conf.save_every = len(train_loader) // 2\n",
    "# conf.board_grad_norm = len(train_loader) // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.120215Z",
     "start_time": "2018-07-01T02:18:18.382039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_ds = Coco_dataset(conf,conf.train_path,conf.train_anno_path,maps)\n",
    "train_loader = DataLoader(train_ds,batch_size=conf.batch_size,shuffle=True,collate_fn=coco_collate_fn,pin_memory=True,num_workers=conf.num_workers)\n",
    "val_dataset = datasets.CocoDetection(conf.val_path, conf.val_anno_path)\n",
    "val_dataset.maps = maps\n",
    "conf.transform_test = trans.Compose([\n",
    "    trans.Resize([conf.input_size,conf.input_size]),\n",
    "    trans.ToTensor(),\n",
    "    trans.Normalize(conf.mean, conf.std)\n",
    "])\n",
    "val_loader = Coco_loader(\n",
    "    conf,\n",
    "    val_dataset,\n",
    "    conf.transform_test,\n",
    "    batch_size=conf.batch_size,\n",
    "    hflip=False,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.138217Z",
     "start_time": "2018-07-01T02:18:28.121543Z"
    }
   },
   "outputs": [],
   "source": [
    "paras = [*model.parameters()][159:]\n",
    "\n",
    "optimizer = optim.SGD(paras,lr=1e-5,momentum=0.9,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.154923Z",
     "start_time": "2018-07-01T02:18:28.139375Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo = Yolo(conf,model,train_loader,val_loader,None,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:18:41.108042Z",
     "start_time": "2018-06-30T23:18:35.067021Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "imgs,bboxes_group,labels_group = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:18:41.168402Z",
     "start_time": "2018-06-30T23:18:41.109800Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "imgs = imgs.to(conf.device)\n",
    "for i,label in enumerate(labels_group):\n",
    "    labels_group[i] = label.to(conf.device)\n",
    "for i,bboxes in enumerate(bboxes_group):\n",
    "    bboxes_group[i] = bboxes.to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:30:11.523135Z",
     "start_time": "2018-06-30T23:30:11.401912Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "preds = yolo.model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:30:11.523548Z",
     "start_time": "2018-06-30T23:29:44.442Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "preds.loss_feats[0].shape,preds.loss_feats[1].shape,preds.loss_feats[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:30:11.524192Z",
     "start_time": "2018-06-30T23:29:44.444Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "preds.pred_bboxes_group[0].shape,preds.pred_bboxes_group[1].shape,preds.pred_bboxes_group[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T00:34:03.935160Z",
     "start_time": "2018-07-01T00:33:40.628Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "yolo.model.head.anchors_group[0],yolo.model.head.anchors_group[1],yolo.model.head.anchors_group[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.353389Z",
     "start_time": "2018-07-01T02:18:28.156003Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs,labels_group,bboxes_group = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.372071Z",
     "start_time": "2018-07-01T02:18:28.354635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.no_grad"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.394496Z",
     "start_time": "2018-07-01T02:18:28.373210Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = imgs.to(conf.device)\n",
    "for i,label in enumerate(labels_group):\n",
    "    labels_group[i] = label.to(conf.device)\n",
    "for i,bboxes in enumerate(bboxes_group):\n",
    "    bboxes_group[i] = bboxes.to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.412275Z",
     "start_time": "2018-07-01T02:18:28.395628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo.model.eval()\n",
    "# yolo.model.train()\n",
    "yolo.model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.428599Z",
     "start_time": "2018-07-01T02:18:28.413307Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.473782Z",
     "start_time": "2018-07-01T02:18:28.429546Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = yolo.model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:19:13.288850Z",
     "start_time": "2018-07-01T02:19:13.115946Z"
    }
   },
   "outputs": [],
   "source": [
    "targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "                conf, preds.pred_bboxes_group, bboxes_group, labels_group,\n",
    "                yolo.model.head.anchors_group, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:19:14.698186Z",
     "start_time": "2018-07-01T02:19:14.673802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-02 *\n",
       "       [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  7.6035,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  6.9783,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0][0,0,:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:18:28.661264Z",
     "start_time": "2018-07-01T02:18:28.474965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-05 *\n",
       "       [[-0.2247,  1.6529,  0.6032, -0.0218, -0.2112,  0.8989,  0.4619,\n",
       "          4.0221,  3.3634,  1.1091,  2.0642,  0.2622,  2.4415],\n",
       "        [-0.4093, -0.1864, -0.5303, -0.6787, -1.1372, -0.8606, -0.2409,\n",
       "         -0.1790, -0.0450,  0.1145, -0.0065, -0.1989,  1.5258],\n",
       "        [-0.5671, -0.4566, -0.5687, -1.0066, -1.2815, -1.0193, -0.4439,\n",
       "         -0.3597, -0.3292, -0.1940, -0.0012, -0.4530, -0.1263],\n",
       "        [-0.5763, -0.4204, -0.6985, -0.9281, -1.3681, -1.1011, -0.9010,\n",
       "         -0.7337, -1.0654, -0.8913, -0.4209, -0.5206, -0.1571],\n",
       "        [-0.3178, -0.4637, -0.9853, -0.8628, -1.1132, -0.9855, -0.7026,\n",
       "         -0.9720, -0.7557, -0.3746, -0.6876, -0.5944, -0.1568],\n",
       "        [-0.3854, -0.2844, -0.4701, -0.4231, -0.2201, -0.3224, -0.3382,\n",
       "         -0.9660, -0.8575, -0.5539, -0.7063, -0.6363,  0.9414],\n",
       "        [-0.6017, -0.2274, -0.5819,  0.6758,  1.4849, -0.0612, -0.1687,\n",
       "         -0.6444, -1.0186, -0.7836, -0.6156, -0.1500,  3.7273],\n",
       "        [-0.4848, -0.5405, -0.5653, -0.4069,  0.8652, -0.3247,  1.4040,\n",
       "         -0.4502, -0.5336, -0.7308, -0.2090, -0.2122,  7.0956],\n",
       "        [-0.8353, -0.3387, -0.6641, -0.3434,  0.8385, -0.2718, -0.4286,\n",
       "         -0.5264, -0.8576, -0.4975, -0.4530,  0.4774,  4.8302],\n",
       "        [-0.4955, -0.3773, -0.5307, -0.0393, -0.0704, -0.1865, -0.2843,\n",
       "         -0.4736, -0.8096, -0.7191, -0.3002,  2.2918,  3.2610],\n",
       "        [-0.8147, -0.0435, -0.1482, -0.0307, -0.1600, -0.1482,  1.5624,\n",
       "          0.8682, -0.2325, -0.1339, -0.1344,  1.3247,  2.3187],\n",
       "        [-0.5133, -0.1021,  2.1215, -0.4434, -0.2833,  0.1574,  0.8415,\n",
       "          2.4703, -0.1247,  0.2612, -0.1513, -0.2626, -0.0338],\n",
       "        [-0.5162, -0.4771, -0.3395, -0.0042, -0.1267, -0.0338,  0.0749,\n",
       "         -0.1213, -0.1664, -0.0832, -0.3033, -0.4027, -0.0345]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.loss_feats[0][0,0,:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:11:00.921782Z",
     "start_time": "2018-07-01T02:11:00.855495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1274,  0.1476,  0.0531,  0.0618,  0.1638,  0.0323, -0.0022,\n",
       "         -0.0010,  0.0960,  0.0013, -0.0084,  0.0162,  0.0846],\n",
       "        [ 0.0840, -0.0108, -0.0113, -0.0048,  0.1058,  0.0622,  0.0556,\n",
       "         -0.0001,  0.1340, -0.0084,  0.0045,  0.0369,  0.1134],\n",
       "        [ 0.0526,  0.0696, -0.0188, -0.0100,  0.0093, -0.0269, -0.0062,\n",
       "          0.0656,  0.0862,  0.1236, -0.0148,  0.0566, -0.0083],\n",
       "        [ 0.0528, -0.0076,  0.0203, -0.0051, -0.0133, -0.0058, -0.0091,\n",
       "         -0.0087, -0.0005, -0.0156, -0.0180, -0.0270, -0.0048],\n",
       "        [ 0.1384, -0.0087,  0.0508,  0.0442, -0.0071, -0.0067, -0.0004,\n",
       "         -0.0036, -0.0132,  0.0217, -0.0264, -0.0212,  0.0021],\n",
       "        [ 0.1000, -0.0032,  0.0548,  0.0964,  0.0267,  0.0465,  0.1323,\n",
       "          0.1315,  0.0181,  0.0101,  0.2290,  0.0597,  0.0538],\n",
       "        [ 0.0511,  0.0624,  0.0990,  0.0202, -0.0178,  0.0071, -0.0001,\n",
       "          0.1563,  0.0213, -0.0111,  0.1055,  0.0141, -0.0005],\n",
       "        [-0.0032,  0.0168, -0.0143,  0.0354, -0.0133, -0.0079,  0.1202,\n",
       "          0.0222, -0.0074,  0.0594,  0.0924,  0.0845,  0.1302],\n",
       "        [-0.0108, -0.0016, -0.0135, -0.0072, -0.0003, -0.0058, -0.0024,\n",
       "          0.0643, -0.0102,  0.0449,  0.0016,  0.0589,  0.1730],\n",
       "        [-0.0072, -0.0227, -0.0143, -0.0110, -0.0055, -0.0099, -0.0085,\n",
       "          0.0249,  0.0494, -0.0139, -0.0077,  0.0981,  0.1903],\n",
       "        [ 0.0369, -0.0163, -0.0033, -0.0115, -0.0036, -0.0222, -0.0054,\n",
       "          0.0429, -0.0076,  0.0689,  0.0456,  0.0700,  0.1191],\n",
       "        [ 0.0561, -0.0004,  0.0130, -0.0047, -0.0032, -0.0115, -0.0060,\n",
       "         -0.0061, -0.0041, -0.0060, -0.0015,  0.0256,  0.0248],\n",
       "        [ 0.0352,  0.0696,  0.0761, -0.0050, -0.0033, -0.0029,  0.0176,\n",
       "          0.0714,  0.0625,  0.0339, -0.0012,  0.0401,  0.0235]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.loss_feats[0][0,0,:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:13:12.178616Z",
     "start_time": "2018-07-01T02:13:12.006074Z"
    }
   },
   "outputs": [],
   "source": [
    "targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "                conf, preds.pred_bboxes_group, bboxes_group, labels_group,\n",
    "                yolo.model.head.anchors_group, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:13:12.435300Z",
     "start_time": "2018-07-01T02:13:12.410863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-02 *\n",
       "       [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  7.6035,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  6.9783,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0][0,0,:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:13:14.933063Z",
     "start_time": "2018-07-01T02:13:14.902145Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = yolo_loss(conf, preds.loss_feats, targets, gt_mask,conf_weight, coord_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:13:15.150025Z",
     "start_time": "2018-07-01T02:13:15.094222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "losses(loss_total=tensor(39224.7891, device='cuda:0'), loss_xy=30294.765625, loss_wh=6826.3720703125, loss_conf=1868.921142578125, loss_cls=234.73077392578125)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:32:06.371607Z",
     "start_time": "2018-07-01T01:32:06.350675Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo.seen = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:52:33.880128Z",
     "start_time": "2018-07-01T01:51:12.471491Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo.evaluate(conf,5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T02:17:47.426344Z",
     "start_time": "2018-07-01T02:17:46.786559Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms as trans\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.vis_utils import *\n",
    "from utils.box_utils import *\n",
    "from utils.dataset_tools import *\n",
    "from utils.utils import *\n",
    "from models.Yolo_head import Yolo_loss\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def calc_preds(conf, preds, object_only = True):\n",
    "    bboxes_group = []\n",
    "    labels_group = []\n",
    "    nB = len(preds.loss_feats[0])\n",
    "    with torch.no_grad():\n",
    "        for nb in range(nB):\n",
    "            bboxes_predicted = []\n",
    "            cls_predicted = []\n",
    "            conf_predicted = []\n",
    "            for l in range(3):\n",
    "                confidences = preds.loss_feats[l][nb][...,4]\n",
    "                cls_conf_preds,classes = torch.max(preds.loss_feats[l][nb][...,5:],dim=-1)\n",
    "                bboxes = preds.pred_bboxes_group[l][nb]\n",
    "                if object_only:\n",
    "                    final_conf = confidences\n",
    "                else:\n",
    "                    final_conf = confidences * cls_conf_preds\n",
    "                predicted_mask = final_conf > conf.predict_confidence_threshold\n",
    "                bboxes_predicted.append(bboxes[predicted_mask])\n",
    "                cls_predicted.append(classes[predicted_mask])\n",
    "                conf_predicted.append(final_conf[predicted_mask])\n",
    "            bboxes_predicted = torch.cat(bboxes_predicted)\n",
    "            cls_predicted = torch.cat(cls_predicted)\n",
    "            conf_predicted = torch.cat(conf_predicted)\n",
    "            if len(bboxes_predicted) != 0:\n",
    "                picked_boxes = non_max_suppression(xcycwh_2_xywh(bboxes_predicted).cpu().numpy(),\n",
    "                                                   conf_predicted.cpu().numpy(),\n",
    "                                                   conf.pred_nms_iou_threshold)\n",
    "                bboxes_group.append(bboxes_predicted[picked_boxes])\n",
    "                labels_group.append(cls_predicted[picked_boxes])\n",
    "            else:\n",
    "                bboxes_group.append(torch.tensor([0.,0.,0.,0.]).unsqueeze(0).to(conf.device))\n",
    "                labels_group.append(torch.tensor([0]).to(conf.device))             \n",
    "    return bboxes_group,labels_group\n",
    "\n",
    "class Yolo(object):\n",
    "    def __init__(self,\n",
    "                 conf,\n",
    "                 model=None,\n",
    "                 train_loader=None,\n",
    "                 val_loader=None,\n",
    "                 writer=None,\n",
    "                 optimizer=None,\n",
    "                 step=0,\n",
    "                 seen=0):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.writer = writer\n",
    "        self.step = step\n",
    "        self.seen = seen\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def save_state(self,conf,val_loss,extra=None):\n",
    "        torch.save(self.model.state_dict(),conf.model_path/\n",
    "                   ('{}_val_loss:{}_model_seen:{}_step:{}_{}.pth'.format(get_time(),val_loss,self.seen,self.step,extra)))\n",
    "        torch.save(self.optimizer.state_dict(),conf.model_path/\n",
    "                    ('{}_val_loss:{}_optimizer_seen:{}_step:{}_{}.pth'.format(get_time(),val_loss,self.seen,self.step,extra)))\n",
    "        \n",
    "    def predict(self,conf,imgs,object_only=True,return_img=False):\n",
    "        imgs = imgs.to(conf.device)\n",
    "        nB = len(imgs)\n",
    "        self.model.eval()\n",
    "        preds = self.model(imgs)\n",
    "        bboxes_group,labels_group = calc_preds(conf, preds, object_only = conf.object_only)\n",
    "        self.model.train()         \n",
    "        if return_img:\n",
    "            return show_util(conf,0,imgs,labels_group,bboxes_group,self.train_loader.dataset.maps[2])\n",
    "        else:\n",
    "            return bboxes_group,labels_group\n",
    "    \n",
    "    def evaluate(self, conf, batches=100 ,verbose=False):\n",
    "        self.val_loader.current = 0\n",
    "        self.model.eval()\n",
    "        if verbose:\n",
    "            loader = tqdm(iter(self.val_loader),total = batches)\n",
    "        else:\n",
    "            loader = iter(self.val_loader)\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_loss_xy = 0.\n",
    "        running_loss_wh = 0.\n",
    "        running_loss_conf = 0.\n",
    "        running_loss_cls = 0.\n",
    "        n_correct = 0\n",
    "        n_gt = 0\n",
    "        n_pred = 0\n",
    "        cls_correct_num = 0\n",
    "        batch_count = 0    \n",
    "        warm_up = self.seen < conf.warm_up_img_num\n",
    "        with torch.no_grad():         \n",
    "            for imgs,labels_group,bboxes_group in loader:   \n",
    "                if batch_count < batches:\n",
    "                    imgs = imgs.to(conf.device)\n",
    "                    for i,label in enumerate(labels_group):\n",
    "                        labels_group[i] = label.to(conf.device)\n",
    "                    for i,bboxes in enumerate(bboxes_group):\n",
    "                        bboxes_group[i] = bboxes.to(conf.device)\n",
    "                    preds = self.model(imgs)\n",
    "\n",
    "                    targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "                        conf, preds.pred_bboxes_group, bboxes_group, labels_group,\n",
    "                        yolo.model.head.anchors_group, warm_up)\n",
    "                    \n",
    "                    pdb.set_trace()\n",
    "\n",
    "                    losses = yolo_loss(conf, preds.loss_feats, targets, gt_mask,conf_weight, coord_mask)\n",
    "                    running_loss += losses.loss_total.item()\n",
    "                    running_loss_xy += losses.loss_xy\n",
    "                    running_loss_wh += losses.loss_wh\n",
    "                    running_loss_conf += losses.loss_conf\n",
    "                    running_loss_cls += losses.loss_cls                    \n",
    "                    \n",
    "                    bboxes_group_pred,labels_group_pred = calc_preds(conf, preds, object_only = conf.object_only)\n",
    "\n",
    "                    for nb in range(len(imgs)):\n",
    "                        pred_bboxes = bboxes_group_pred[nb]\n",
    "                        gt_bboxes = bboxes_group[nb]\n",
    "                        ious = cal_ious_xcycwh(pred_bboxes, gt_bboxes).to(conf.device)\n",
    "                        max_matched_iou_gt,max_matched_box_idx_gt = torch.max(ious,dim=1)\n",
    "                        matched_mask = max_matched_iou_gt > conf.evaluate_iou_threshold\n",
    "                        matched_classes = labels_group_pred[nb][matched_mask]\n",
    "                        cls_correct_num += torch.sum(matched_classes == \\\n",
    "                                                     labels_group[nb][max_matched_box_idx_gt][matched_mask]).item()\n",
    "                        n_pred += len(pred_bboxes)\n",
    "                        n_gt += len(gt_bboxes)\n",
    "                        n_correct += torch.sum(matched_mask).item()\n",
    "                    batch_count += 1\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "        precision = n_correct/n_gt\n",
    "        recall = n_correct/n_pred\n",
    "        f1 = 2*precision*recall / (precision + recall + 1e-8)\n",
    "        cls_acc = cls_correct_num/n_gt\n",
    "        \n",
    "        self.model.train()\n",
    "        return running_loss/batches,\\\n",
    "                running_loss_xy/batches,\\\n",
    "                running_loss_wh/batches,\\\n",
    "                running_loss_conf/batches,\\\n",
    "                running_loss_cls/batches,\\\n",
    "                precision,recall,f1,cls_acc        \n",
    "    \n",
    "    def find_lr(self,conf,init_value = 1e-8, final_value=10., beta = 0.98,num = None):\n",
    "        if not num:\n",
    "            num = len(self.train_loader) // 5\n",
    "        mult = (final_value / init_value) ** (1/num)\n",
    "        lr = init_value\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        avg_loss = 0.\n",
    "        best_loss = 0.\n",
    "        batch_num = 0\n",
    "        losses = []\n",
    "        log_lrs = []\n",
    "        for imgs,labels_group,bboxes_group in tqdm(iter(self.train_loader),total=num):\n",
    "            batch_num += 1\n",
    "            imgs = imgs.to(conf.device)\n",
    "            for i,label in enumerate(labels_group):\n",
    "                labels_group[i] = label.to(conf.device)\n",
    "            for i,bboxes in enumerate(bboxes_group):\n",
    "                bboxes_group[i] = bboxes.to(conf.device)            \n",
    "                \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            preds = self.model(imgs)\n",
    "\n",
    "            targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "                conf, preds.pred_bboxes_group, bboxes_group, labels_group,\n",
    "                yolo.model.head.anchors_group, warm_up)\n",
    "\n",
    "            losses = yolo_loss(conf, preds.loss_feats, targets, gt_mask,conf_weight, coord_mask)\n",
    "\n",
    "            #Compute the smoothed loss\n",
    "            avg_loss = beta * avg_loss + (1-beta) *losses.loss_total.item()\n",
    "            self.writer.add_scalar('avg_loss',avg_loss,batch_num)\n",
    "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "            self.writer.add_scalar('smoothed_loss',smoothed_loss,batch_num)\n",
    "            #Stop if the loss is exploding\n",
    "            if batch_num > 1 and smoothed_loss > 10 * best_loss:\n",
    "                print('exited with best_loss at {}'.format(best_loss))\n",
    "                plt.plot(log_lrs[10:-5],losses[10:-5])\n",
    "                return log_lrs, losses\n",
    "            #Record the best loss\n",
    "            if smoothed_loss < best_loss or batch_num==1:\n",
    "                best_loss = smoothed_loss\n",
    "            #Store the values\n",
    "            losses.append(smoothed_loss)\n",
    "            log_lrs.append(math.log10(lr))\n",
    "            self.writer.add_scalar('log_lr',math.log10(lr),batch_num)\n",
    "            #Do the SGD step\n",
    "            losses.loss_total.backward()\n",
    "            self.optimizer.step()\n",
    "            #Update the lr for the next step\n",
    "            lr *= mult\n",
    "            self.optimizer.param_groups[0]['lr'] = lr\n",
    "            if batch_num > num:\n",
    "                return log_lrs, losses \n",
    "    \n",
    "    def train(self, conf, epochs, log):\n",
    "        running_loss = 0.\n",
    "        running_loss_xy = 0.\n",
    "        running_loss_wh = 0.\n",
    "        running_loss_conf = 0.\n",
    "        running_loss_cls = 0.\n",
    "\n",
    "        for e in range(epochs):\n",
    "            self.train_loader.current = 0\n",
    "            for imgs, labels_group, bboxes_group in tqdm(iter(self.train_loader)):\n",
    "\n",
    "                warm_up = True if self.seen < 12800 else False\n",
    "\n",
    "                imgs = imgs.to(conf.device)\n",
    "                for i, label in enumerate(labels_group):\n",
    "                    labels_group[i] = label.to(conf.device)\n",
    "                for i, bboxes in enumerate(bboxes_group):\n",
    "                    bboxes_group[i] = bboxes.to(conf.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                preds = self.model(imgs)\n",
    "\n",
    "                targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "                    conf, preds.pred_bboxes_group, bboxes_group, labels_group,\n",
    "                    yolo.model.head.anchors_group, warm_up)\n",
    "\n",
    "                losses = yolo_loss(conf, preds.loss_feats, targets, gt_mask,conf_weight, coord_mask)\n",
    "\n",
    "                losses.loss_total.backward()\n",
    "\n",
    "                if conf.gdclip:\n",
    "                    clip_grad_norm_log_(\n",
    "                        conf, self.optimizer.param_groups[0]['params'],\n",
    "                        conf.gdclip, self.writer, self.step)\n",
    "\n",
    "                self.optimizer.step()\n",
    "                self.step += 1\n",
    "                self.seen += len(imgs)\n",
    "\n",
    "                running_loss += losses.loss_total.item()\n",
    "                running_loss_xy += losses.loss_xy\n",
    "                running_loss_wh += losses.loss_wh\n",
    "                running_loss_conf += losses.loss_conf\n",
    "                running_loss_cls += losses.loss_cls\n",
    "\n",
    "                if self.step % conf.board_loss_every == 0:\n",
    "                    if warm_up:\n",
    "                        self.writer.add_scalar('loss_warm_up',running_loss / conf.board_loss_every, self.step)\n",
    "                        self.writer.add_scalar('loss_xy_warm_up',running_loss_xy / conf.board_loss_every, self.step)\n",
    "                        self.writer.add_scalar('loss_wh_warm_up',running_loss_wh / conf.board_loss_every, self.step)\n",
    "                        self.writer.add_scalar('loss_conf_warm_up',running_loss_conf / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_cls_warm_up',running_loss_cls / conf.board_loss_every,self.step)\n",
    "                    else:\n",
    "                        self.writer.add_scalar('loss', running_loss / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_xy', running_loss_xy / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_wh', running_loss_wh / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_conf',running_loss_conf / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_cls',running_loss_cls / conf.board_loss_every,self.step)\n",
    "\n",
    "                    running_loss = 0.\n",
    "                    running_loss_xy = 0.\n",
    "                    running_loss_wh = 0.\n",
    "                    running_loss_conf = 0.\n",
    "                    running_loss_cls = 0.\n",
    "                \n",
    "                if self.step % conf.evaluate_every == 0:\n",
    "                    val_loss,\\\n",
    "                    val_loss_xy,\\\n",
    "                    val_loss_wh,\\\n",
    "                    val_loss_conf,\\\n",
    "                    val_loss_cls,\\\n",
    "                    precision,recall,f1,cls_acc = self.evaluate(conf,100,50)\n",
    "\n",
    "                    self.writer.add_scalar('val_loss',val_loss,self.step)\n",
    "                    self.writer.add_scalar('val_loss_xy',val_loss_xy,self.step)\n",
    "                    self.writer.add_scalar('val_loss_wh',val_loss_wh,self.step)\n",
    "                    self.writer.add_scalar('val_loss_conf',val_loss_conf,self.step)\n",
    "                    self.writer.add_scalar('val_loss_cls',val_loss_cls,self.step)\n",
    "                    self.writer.add_scalar('val_precision',precision,self.step)\n",
    "                    self.writer.add_scalar('val_recall',recall,self.step)\n",
    "                    self.writer.add_scalar('val_f1',f1,self.step)\n",
    "                    self.writer.add_scalar('val_cls_acc',cls_acc,self.step)    \n",
    "\n",
    "                if self.step % conf.board_pred_image_every == 0:\n",
    "                    for i in range(20):\n",
    "                        img,_ = self.val_loader.dataset[i]\n",
    "                        img_tensor = self.predict(self.val_loader.transform(img),\n",
    "                                                  conf,\n",
    "                                                  conf.predict_confidence_threshold,\n",
    "                                                  only_objectness=True,\n",
    "                                                  return_img=True)\n",
    "                        self.writer.add_image('pred_image_{}'.format(i),img_tensor,global_step=self.step)\n",
    "\n",
    "                if self.step % conf.save_every == 0:\n",
    "                    self.save_state(conf,val_loss,extra=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T09:59:25.339079Z",
     "start_time": "2018-06-30T09:59:25.126730Z"
    }
   },
   "outputs": [],
   "source": [
    "targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "    conf,\n",
    "    preds.pred_bboxes_group,\n",
    "    bboxes_group,\n",
    "    labels_group,\n",
    "    yolo.model.head.anchors_group,\n",
    "    warm_up=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T10:00:56.950535Z",
     "start_time": "2018-06-30T10:00:56.903674Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = yolo_loss(conf,preds.loss_feats,targets,gt_mask,conf_weight,coord_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T09:59:39.017905Z",
     "start_time": "2018-06-30T09:59:38.996285Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T10:01:11.989838Z",
     "start_time": "2018-06-30T10:01:11.967564Z"
    }
   },
   "outputs": [],
   "source": [
    "losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
