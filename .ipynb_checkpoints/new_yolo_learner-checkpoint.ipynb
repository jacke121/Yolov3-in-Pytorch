{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:04.260197Z",
     "start_time": "2018-07-01T01:30:04.239560Z"
    }
   },
   "outputs": [],
   "source": [
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:05.048806Z",
     "start_time": "2018-07-01T01:30:04.261900Z"
    }
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms as trans\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from models.Yolo_model import Yolo_model, build_targets, yolo_loss\n",
    "import numpy as np\n",
    "# np.seterr(all='raise')\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "# import torch.nn.functional as F\n",
    "from utils.vis_utils import *\n",
    "from utils.box_utils import *\n",
    "from utils.dataset_tools import *\n",
    "from utils.utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "# s\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:16.695693Z",
     "start_time": "2018-07-01T01:30:05.050199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.52s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "conf = edict()\n",
    "\n",
    "conf.coco_anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],\n",
    "                     [59, 119], [116, 90], [156, 198], [373, 326]]\n",
    "conf.train_path = Path('/home/f/nvme/coco2017/train2017/')\n",
    "conf.train_anno_path = Path(\n",
    "    '/home/f/nvme/coco2017/annotations/instances_train2017.json')\n",
    "conf.val_path = Path('/home/f/nvme/coco2017/val2017/')\n",
    "conf.val_anno_path = Path(\n",
    "    '/home/f/nvme/coco2017/annotations/instances_val2017.json')\n",
    "conf.log_path = Path('/home/f/learning/yolo/log')\n",
    "conf.model_path = Path('/home/f/learning/yolo/model')\n",
    "conf.save_path = Path('/home/f/learning/yolo/save')\n",
    "conf.ids_path = 'data/ids.npy'\n",
    "\n",
    "conf.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "maps,correct_id_2_class = get_id_maps(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:19.633112Z",
     "start_time": "2018-07-01T01:30:16.697250Z"
    }
   },
   "outputs": [],
   "source": [
    "conf.num_anchors = 3\n",
    "conf.batch_size = 16\n",
    "conf.input_size = 416\n",
    "conf.scales = [32,16,8]\n",
    "\n",
    "conf.running_norm = 0.\n",
    "# conf.gdclip = 3000.\n",
    "conf.num_workers = 8\n",
    "conf.batch_size = 16\n",
    "conf.gdclip = None\n",
    "conf.coord_scale = 2.\n",
    "conf.noobject_scale = 0.5\n",
    "conf.object_scale = 5\n",
    "conf.class_scale = 5.\n",
    "conf.ignore_thresh = 0.5\n",
    "conf.evaluate_iou_threshold = 0.5\n",
    "conf.predict_confidence_threshold = 0.5\n",
    "conf.pred_nms_iou_threshold = 0.5\n",
    "conf.object_only = True\n",
    "conf.warm_up_img_num = 12800\n",
    "\n",
    "model = Yolo_model(conf)\n",
    "model.to(conf.device)\n",
    "conf.mean = model.res50_pyramid.model.mean\n",
    "conf.std = model.res50_pyramid.model.std\n",
    "\n",
    "conf.mse_loss = nn.MSELoss(size_average=False)\n",
    "conf.bce_loss = nn.BCEWithLogitsLoss(size_average=False)\n",
    "\n",
    "conf.board_loss_every = 5\n",
    "conf.evaluate_every = 5\n",
    "conf.board_pred_image_every = 5\n",
    "# conf.board_loss_every = len(train_loader) // 100\n",
    "# conf.evaluate_every = len(train_loader) // 10\n",
    "# conf.board_pred_image_every = len(train_loader) // 2\n",
    "# conf.save_every = len(train_loader) // 2\n",
    "# conf.board_grad_norm = len(train_loader) // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:29.419213Z",
     "start_time": "2018-07-01T01:30:19.637247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_ds = Coco_dataset(conf,conf.train_path,conf.train_anno_path,maps)\n",
    "train_loader = DataLoader(train_ds,batch_size=conf.batch_size,shuffle=True,collate_fn=coco_collate_fn,pin_memory=True,num_workers=conf.num_workers)\n",
    "val_dataset = datasets.CocoDetection(conf.val_path, conf.val_anno_path)\n",
    "val_dataset.maps = maps\n",
    "conf.transform_test = trans.Compose([\n",
    "    trans.Resize([conf.input_size,conf.input_size]),\n",
    "    trans.ToTensor(),\n",
    "    trans.Normalize(conf.mean, conf.std)\n",
    "])\n",
    "val_loader = Coco_loader(\n",
    "    conf,\n",
    "    val_dataset,\n",
    "    conf.transform_test,\n",
    "    batch_size=conf.batch_size,\n",
    "    hflip=False,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:29.437055Z",
     "start_time": "2018-07-01T01:30:29.420526Z"
    }
   },
   "outputs": [],
   "source": [
    "paras = [*model.parameters()][159:]\n",
    "\n",
    "optimizer = optim.SGD(paras,lr=1e-5,momentum=0.9,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:49:43.755287Z",
     "start_time": "2018-07-01T01:49:43.734401Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo = Yolo(conf,model,train_loader,val_loader,None,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:18:41.108042Z",
     "start_time": "2018-06-30T23:18:35.067021Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "imgs,bboxes_group,labels_group = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:18:41.168402Z",
     "start_time": "2018-06-30T23:18:41.109800Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "imgs = imgs.to(conf.device)\n",
    "for i,label in enumerate(labels_group):\n",
    "    labels_group[i] = label.to(conf.device)\n",
    "for i,bboxes in enumerate(bboxes_group):\n",
    "    bboxes_group[i] = bboxes.to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:30:11.523135Z",
     "start_time": "2018-06-30T23:30:11.401912Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "preds = yolo.model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:30:11.523548Z",
     "start_time": "2018-06-30T23:29:44.442Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "preds.loss_feats[0].shape,preds.loss_feats[1].shape,preds.loss_feats[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T23:30:11.524192Z",
     "start_time": "2018-06-30T23:29:44.444Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "preds.pred_bboxes_group[0].shape,preds.pred_bboxes_group[1].shape,preds.pred_bboxes_group[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T00:34:03.935160Z",
     "start_time": "2018-07-01T00:33:40.628Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "yolo.model.head.anchors_group[0],yolo.model.head.anchors_group[1],yolo.model.head.anchors_group[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:29.652557Z",
     "start_time": "2018-07-01T01:30:29.454838Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs,labels_group,bboxes_group = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:29.671385Z",
     "start_time": "2018-07-01T01:30:29.653779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.no_grad"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:29.693709Z",
     "start_time": "2018-07-01T01:30:29.672461Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = imgs.to(conf.device)\n",
    "for i,label in enumerate(labels_group):\n",
    "    labels_group[i] = label.to(conf.device)\n",
    "for i,bboxes in enumerate(bboxes_group):\n",
    "    bboxes_group[i] = bboxes.to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:29.710853Z",
     "start_time": "2018-07-01T01:30:29.694813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yolo.model.eval()\n",
    "yolo.model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:26:17.977606Z",
     "start_time": "2018-07-01T01:26:17.830851Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:30:39.725988Z",
     "start_time": "2018-07-01T01:30:39.672989Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = yolo.model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:31:48.266002Z",
     "start_time": "2018-07-01T01:31:48.097468Z"
    }
   },
   "outputs": [],
   "source": [
    "targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "                conf, preds.pred_bboxes_group, bboxes_group, labels_group,\n",
    "                yolo.model.head.anchors_group, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:31:48.760988Z",
     "start_time": "2018-07-01T01:31:48.735248Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = yolo_loss(conf, preds.loss_feats, targets, gt_mask,conf_weight, coord_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:31:49.667966Z",
     "start_time": "2018-07-01T01:31:49.645491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "losses(loss_total=tensor(2310.7466, device='cuda:0'), loss_xy=29.64359474182129, loss_wh=21.051342010498047, loss_conf=2027.60009765625, loss_cls=232.45176696777344)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:32:06.371607Z",
     "start_time": "2018-07-01T01:32:06.350675Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo.seen = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:49:55.215319Z",
     "start_time": "2018-07-01T01:49:52.508865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3449546586e04416af22ffc511a3ab90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31534.21171875,\n",
       " 29519.810546875,\n",
       " 5.470092391967773,\n",
       " 1853.1540283203126,\n",
       " 155.77691040039062,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo.evaluate(conf,5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T01:49:36.480674Z",
     "start_time": "2018-07-01T01:49:36.436950Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms as trans\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.vis_utils import *\n",
    "from utils.box_utils import *\n",
    "from utils.dataset_tools import *\n",
    "from utils.utils import *\n",
    "from models.Yolo_head import Yolo_loss\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def calc_preds(conf, preds, object_only = True):\n",
    "    bboxes_group = []\n",
    "    labels_group = []\n",
    "    nB = len(preds.loss_feats[0])\n",
    "    with torch.no_grad():\n",
    "        for nb in range(nB):\n",
    "            bboxes_predicted = []\n",
    "            cls_predicted = []\n",
    "            conf_predicted = []\n",
    "            for l in range(3):\n",
    "                confidences = preds.loss_feats[l][nb][...,4]\n",
    "                cls_conf_preds,classes = torch.max(preds.loss_feats[l][nb][...,5:],dim=-1)\n",
    "                bboxes = preds.pred_bboxes_group[l][nb]\n",
    "                if object_only:\n",
    "                    final_conf = confidences\n",
    "                else:\n",
    "                    final_conf = confidences * cls_conf_preds\n",
    "                predicted_mask = final_conf > conf.predict_confidence_threshold\n",
    "                bboxes_predicted.append(bboxes[predicted_mask])\n",
    "                cls_predicted.append(classes[predicted_mask])\n",
    "                conf_predicted.append(final_conf[predicted_mask])\n",
    "            bboxes_predicted = torch.cat(bboxes_predicted)\n",
    "            cls_predicted = torch.cat(cls_predicted)\n",
    "            conf_predicted = torch.cat(conf_predicted)\n",
    "            if len(bboxes_predicted) != 0:\n",
    "                picked_boxes = non_max_suppression(xcycwh_2_xywh(bboxes_predicted).cpu().numpy(),\n",
    "                                                   conf_predicted.cpu().numpy(),\n",
    "                                                   conf.pred_nms_iou_threshold)\n",
    "                bboxes_group.append(bboxes_predicted[picked_boxes])\n",
    "                labels_group.append(cls_predicted[picked_boxes])\n",
    "            else:\n",
    "                bboxes_group.append(torch.tensor([0.,0.,0.,0.]).unsqueeze(0).to(conf.device))\n",
    "                labels_group.append(torch.tensor([0]).to(conf.device))             \n",
    "    return bboxes_group,labels_group\n",
    "\n",
    "class Yolo(object):\n",
    "    def __init__(self,\n",
    "                 conf,\n",
    "                 model=None,\n",
    "                 train_loader=None,\n",
    "                 val_loader=None,\n",
    "                 writer=None,\n",
    "                 optimizer=None,\n",
    "                 step=0,\n",
    "                 seen=0):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.writer = writer\n",
    "        self.step = step\n",
    "        self.seen = seen\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def save_state(self,conf,val_loss,extra=None):\n",
    "        torch.save(self.model.state_dict(),conf.model_path/\n",
    "                   ('{}_val_loss:{}_model_seen:{}_step:{}_{}.pth'.format(get_time(),val_loss,self.seen,self.step,extra)))\n",
    "        torch.save(self.optimizer.state_dict(),conf.model_path/\n",
    "                    ('{}_val_loss:{}_optimizer_seen:{}_step:{}_{}.pth'.format(get_time(),val_loss,self.seen,self.step,extra)))\n",
    "        \n",
    "    def predict(self,conf,imgs,object_only=True,return_img=False):\n",
    "        imgs = imgs.to(conf.device)\n",
    "        nB = len(imgs)\n",
    "        self.model.eval()\n",
    "        preds = self.model(imgs)\n",
    "        bboxes_group,labels_group = calc_preds(conf, preds, object_only = conf.object_only)\n",
    "        self.model.train()         \n",
    "        if return_img:\n",
    "            return show_util(conf,0,imgs,labels_group,bboxes_group,self.train_loader.dataset.maps[2])\n",
    "        else:\n",
    "            return bboxes_group,labels_group\n",
    "    \n",
    "    def evaluate(self, conf, batches=100 ,verbose=False):\n",
    "        self.val_loader.current = 0\n",
    "        self.model.eval()\n",
    "        if verbose:\n",
    "            loader = tqdm(iter(self.val_loader),total = batches)\n",
    "        else:\n",
    "            loader = iter(self.val_loader)\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_loss_xy = 0.\n",
    "        running_loss_wh = 0.\n",
    "        running_loss_conf = 0.\n",
    "        running_loss_cls = 0.\n",
    "        n_correct = 0\n",
    "        n_gt = 0\n",
    "        n_pred = 0\n",
    "        cls_correct_num = 0\n",
    "        batch_count = 0    \n",
    "        warm_up = self.seen < conf.warm_up_img_num\n",
    "        with torch.no_grad():         \n",
    "            for imgs,labels_group,bboxes_group in loader:   \n",
    "                if batch_count < batches:\n",
    "                    imgs = imgs.to(conf.device)\n",
    "                    for i,label in enumerate(labels_group):\n",
    "                        labels_group[i] = label.to(conf.device)\n",
    "                    for i,bboxes in enumerate(bboxes_group):\n",
    "                        bboxes_group[i] = bboxes.to(conf.device)\n",
    "                    preds = self.model(imgs)\n",
    "\n",
    "                    targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "                        conf, preds.pred_bboxes_group, bboxes_group, labels_group,\n",
    "                        yolo.model.head.anchors_group, warm_up)\n",
    "                    \n",
    "                    pdb.set_trace()\n",
    "\n",
    "                    losses = yolo_loss(conf, preds.loss_feats, targets, gt_mask,conf_weight, coord_mask)\n",
    "                    running_loss += losses.loss_total.item()\n",
    "                    running_loss_xy += losses.loss_xy\n",
    "                    running_loss_wh += losses.loss_wh\n",
    "                    running_loss_conf += losses.loss_conf\n",
    "                    running_loss_cls += losses.loss_cls                    \n",
    "                    \n",
    "                    bboxes_group_pred,labels_group_pred = calc_preds(conf, preds, object_only = conf.object_only)\n",
    "\n",
    "                    for nb in range(len(imgs)):\n",
    "                        pred_bboxes = bboxes_group_pred[nb]\n",
    "                        gt_bboxes = bboxes_group[nb]\n",
    "                        ious = cal_ious_xcycwh(pred_bboxes, gt_bboxes).to(conf.device)\n",
    "                        max_matched_iou_gt,max_matched_box_idx_gt = torch.max(ious,dim=1)\n",
    "                        matched_mask = max_matched_iou_gt > conf.evaluate_iou_threshold\n",
    "                        matched_classes = labels_group_pred[nb][matched_mask]\n",
    "                        cls_correct_num += torch.sum(matched_classes == \\\n",
    "                                                     labels_group[nb][max_matched_box_idx_gt][matched_mask]).item()\n",
    "                        n_pred += len(pred_bboxes)\n",
    "                        n_gt += len(gt_bboxes)\n",
    "                        n_correct += torch.sum(matched_mask).item()\n",
    "                    batch_count += 1\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "        precision = n_correct/n_gt\n",
    "        recall = n_correct/n_pred\n",
    "        f1 = 2*precision*recall / (precision + recall + 1e-8)\n",
    "        cls_acc = cls_correct_num/n_gt\n",
    "        \n",
    "        self.model.train()\n",
    "        return running_loss/batches,\\\n",
    "                running_loss_xy/batches,\\\n",
    "                running_loss_wh/batches,\\\n",
    "                running_loss_conf/batches,\\\n",
    "                running_loss_cls/batches,\\\n",
    "                precision,recall,f1,cls_acc        \n",
    "    \n",
    "    def find_lr(self,conf,init_value = 1e-8, final_value=10., beta = 0.98,num = None):\n",
    "        if not num:\n",
    "            num = len(self.train_loader) // 5\n",
    "        mult = (final_value / init_value) ** (1/num)\n",
    "        lr = init_value\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        avg_loss = 0.\n",
    "        best_loss = 0.\n",
    "        batch_num = 0\n",
    "        losses = []\n",
    "        log_lrs = []\n",
    "        for imgs,labels_group,bboxes_group in tqdm(iter(self.train_loader),total=num):\n",
    "            batch_num += 1\n",
    "            imgs = imgs.to(conf.device)\n",
    "            for i,label in enumerate(labels_group):\n",
    "                labels_group[i] = label.to(conf.device)\n",
    "            for i,bboxes in enumerate(bboxes_group):\n",
    "                bboxes_group[i] = bboxes.to(conf.device)            \n",
    "                \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            preds = self.model(imgs)\n",
    "\n",
    "            targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "                conf, preds.pred_bboxes_group, bboxes_group, labels_group,\n",
    "                yolo.model.head.anchors_group, warm_up)\n",
    "\n",
    "            losses = yolo_loss(conf, preds.loss_feats, targets, gt_mask,conf_weight, coord_mask)\n",
    "\n",
    "            #Compute the smoothed loss\n",
    "            avg_loss = beta * avg_loss + (1-beta) *losses.loss_total.item()\n",
    "            self.writer.add_scalar('avg_loss',avg_loss,batch_num)\n",
    "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "            self.writer.add_scalar('smoothed_loss',smoothed_loss,batch_num)\n",
    "            #Stop if the loss is exploding\n",
    "            if batch_num > 1 and smoothed_loss > 10 * best_loss:\n",
    "                print('exited with best_loss at {}'.format(best_loss))\n",
    "                plt.plot(log_lrs[10:-5],losses[10:-5])\n",
    "                return log_lrs, losses\n",
    "            #Record the best loss\n",
    "            if smoothed_loss < best_loss or batch_num==1:\n",
    "                best_loss = smoothed_loss\n",
    "            #Store the values\n",
    "            losses.append(smoothed_loss)\n",
    "            log_lrs.append(math.log10(lr))\n",
    "            self.writer.add_scalar('log_lr',math.log10(lr),batch_num)\n",
    "            #Do the SGD step\n",
    "            losses.loss_total.backward()\n",
    "            self.optimizer.step()\n",
    "            #Update the lr for the next step\n",
    "            lr *= mult\n",
    "            self.optimizer.param_groups[0]['lr'] = lr\n",
    "            if batch_num > num:\n",
    "                return log_lrs, losses \n",
    "    \n",
    "    def train(self, conf, epochs, log):\n",
    "        running_loss = 0.\n",
    "        running_loss_xy = 0.\n",
    "        running_loss_wh = 0.\n",
    "        running_loss_conf = 0.\n",
    "        running_loss_cls = 0.\n",
    "\n",
    "        for e in range(epochs):\n",
    "            self.train_loader.current = 0\n",
    "            for imgs, labels_group, bboxes_group in tqdm(iter(self.train_loader)):\n",
    "\n",
    "                warm_up = True if self.seen < 12800 else False\n",
    "\n",
    "                imgs = imgs.to(conf.device)\n",
    "                for i, label in enumerate(labels_group):\n",
    "                    labels_group[i] = label.to(conf.device)\n",
    "                for i, bboxes in enumerate(bboxes_group):\n",
    "                    bboxes_group[i] = bboxes.to(conf.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                preds = self.model(imgs)\n",
    "\n",
    "                targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "                    conf, preds.pred_bboxes_group, bboxes_group, labels_group,\n",
    "                    yolo.model.head.anchors_group, warm_up)\n",
    "\n",
    "                losses = yolo_loss(conf, preds.loss_feats, targets, gt_mask,conf_weight, coord_mask)\n",
    "\n",
    "                losses.loss_total.backward()\n",
    "\n",
    "                if conf.gdclip:\n",
    "                    clip_grad_norm_log_(\n",
    "                        conf, self.optimizer.param_groups[0]['params'],\n",
    "                        conf.gdclip, self.writer, self.step)\n",
    "\n",
    "                self.optimizer.step()\n",
    "                self.step += 1\n",
    "                self.seen += len(imgs)\n",
    "\n",
    "                running_loss += losses.loss_total.item()\n",
    "                running_loss_xy += losses.loss_xy\n",
    "                running_loss_wh += losses.loss_wh\n",
    "                running_loss_conf += losses.loss_conf\n",
    "                running_loss_cls += losses.loss_cls\n",
    "\n",
    "                if self.step % conf.board_loss_every == 0:\n",
    "                    if warm_up:\n",
    "                        self.writer.add_scalar('loss_warm_up',running_loss / conf.board_loss_every, self.step)\n",
    "                        self.writer.add_scalar('loss_xy_warm_up',running_loss_xy / conf.board_loss_every, self.step)\n",
    "                        self.writer.add_scalar('loss_wh_warm_up',running_loss_wh / conf.board_loss_every, self.step)\n",
    "                        self.writer.add_scalar('loss_conf_warm_up',running_loss_conf / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_cls_warm_up',running_loss_cls / conf.board_loss_every,self.step)\n",
    "                    else:\n",
    "                        self.writer.add_scalar('loss', running_loss / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_xy', running_loss_xy / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_wh', running_loss_wh / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_conf',running_loss_conf / conf.board_loss_every,self.step)\n",
    "                        self.writer.add_scalar('loss_cls',running_loss_cls / conf.board_loss_every,self.step)\n",
    "\n",
    "                    running_loss = 0.\n",
    "                    running_loss_xy = 0.\n",
    "                    running_loss_wh = 0.\n",
    "                    running_loss_conf = 0.\n",
    "                    running_loss_cls = 0.\n",
    "                \n",
    "                if self.step % conf.evaluate_every == 0:\n",
    "                    val_loss,\\\n",
    "                    val_loss_xy,\\\n",
    "                    val_loss_wh,\\\n",
    "                    val_loss_conf,\\\n",
    "                    val_loss_cls,\\\n",
    "                    precision,recall,f1,cls_acc = self.evaluate(conf,100,50)\n",
    "\n",
    "                    self.writer.add_scalar('val_loss',val_loss,self.step)\n",
    "                    self.writer.add_scalar('val_loss_xy',val_loss_xy,self.step)\n",
    "                    self.writer.add_scalar('val_loss_wh',val_loss_wh,self.step)\n",
    "                    self.writer.add_scalar('val_loss_conf',val_loss_conf,self.step)\n",
    "                    self.writer.add_scalar('val_loss_cls',val_loss_cls,self.step)\n",
    "                    self.writer.add_scalar('val_precision',precision,self.step)\n",
    "                    self.writer.add_scalar('val_recall',recall,self.step)\n",
    "                    self.writer.add_scalar('val_f1',f1,self.step)\n",
    "                    self.writer.add_scalar('val_cls_acc',cls_acc,self.step)    \n",
    "\n",
    "                if self.step % conf.board_pred_image_every == 0:\n",
    "                    for i in range(20):\n",
    "                        img,_ = self.val_loader.dataset[i]\n",
    "                        img_tensor = self.predict(self.val_loader.transform(img),\n",
    "                                                  conf,\n",
    "                                                  conf.predict_confidence_threshold,\n",
    "                                                  only_objectness=True,\n",
    "                                                  return_img=True)\n",
    "                        self.writer.add_image('pred_image_{}'.format(i),img_tensor,global_step=self.step)\n",
    "\n",
    "                if self.step % conf.save_every == 0:\n",
    "                    self.save_state(conf,val_loss,extra=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T09:59:25.339079Z",
     "start_time": "2018-06-30T09:59:25.126730Z"
    }
   },
   "outputs": [],
   "source": [
    "targets, gt_mask, conf_weight, coord_mask = build_targets(\n",
    "    conf,\n",
    "    preds.pred_bboxes_group,\n",
    "    bboxes_group,\n",
    "    labels_group,\n",
    "    yolo.model.head.anchors_group,\n",
    "    warm_up=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T10:00:56.950535Z",
     "start_time": "2018-06-30T10:00:56.903674Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = yolo_loss(conf,preds.loss_feats,targets,gt_mask,conf_weight,coord_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T09:59:39.017905Z",
     "start_time": "2018-06-30T09:59:38.996285Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T10:01:11.989838Z",
     "start_time": "2018-06-30T10:01:11.967564Z"
    }
   },
   "outputs": [],
   "source": [
    "losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
