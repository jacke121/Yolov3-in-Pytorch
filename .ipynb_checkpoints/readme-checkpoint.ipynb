{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This implementation  is not 100% same with the original version !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### The diffrence between this repo and the original [YOLOv3][paperlink]:\n",
    "[paperlink]: https://pjreddie.com/media/files/papers/YOLOv3.pdf\n",
    "1. Using Resnet50 as detection backbone instead of Darknet53.\n",
    "2. Switch the individual binary classifier with softmax cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Things that have been done:\n",
    "1. Full pytorch and numpy implementation of YOLOv3 training and detection\n",
    "2. Pytorch 0.4 codes\n",
    "2. Multi-Scale Training mentioned in the paper\n",
    "-> so far as I noticed, this one is not implemented by a lot of posts about yolo out there.\n",
    "5. lots of data augmentation,thanks to [imgaug][imgaug link]\n",
    "3. training in coco2017 dataset \n",
    "[imgaug link]:https://github.com/aleju/imgaug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### How to use\n",
    "First, clone this repo by input:\n",
    "```\n",
    "git clone https://github.com/TreB1eN/Yolov3-in-Pytorch.git\n",
    "```\n",
    "#### Detection:\n",
    "1. Secondly, download the trained model from cloud drive into data/model folder\n",
    "\n",
    "    - Google Drive:\n",
    "        - [Cuda Model download][cuda model google link]:\n",
    "        - [CPU Model download][cpu model google link]:\n",
    "\n",
    "    - Baidu Netdisk:\n",
    "        - [Cuda Model download][cuda model baidu link]:\n",
    "        - [CPU Model download][cpu model baidu link]:\n",
    "\n",
    "2. For detection in single image, please run\n",
    "```\n",
    "python detect_on_image.py -f input_image_path -o output_image_path -l detection_level\n",
    "```\n",
    "3. For detection in video, please run\n",
    "```\n",
    "python detect_on_video.py -f input_video_path -o output_video_path -l detection_level\n",
    "```\n",
    "4. For detection in camera, please run\n",
    "```\n",
    "python detect_on_camera.py -l detection_level\n",
    "```\n",
    "- - -\n",
    "#### Training:\n",
    "1. download train2017.zip, val2017.zip and annotations_trainval2017.zip from [coco website][coco_address] to data/coco2017\n",
    "2. ```\n",
    "    unzip data/coco2017/train2017.zip\n",
    "    unzip data/coco2017/val2017.zip\n",
    "    unzip data/coco2017/annotations_trainval2017.zip\n",
    "    ```\n",
    "3. run\n",
    "    ```\n",
    "    python train.py\n",
    "    ```\n",
    "    Details and parameters are in the codes\n",
    "\n",
    "[cuda model google link]: https://drive.google.com/open?id=1VuA2SIUYat6bE6-8hvdGLCy1sDrmwK7z\n",
    "[cpu model google link]: https://drive.google.com/open?id=1xN-8gRId8JfW0dgotBtueOUqCKZfj0UF\n",
    "[cuda model baidu link]: https://pan.baidu.com/s/1H0gBY_CsRXmyxaV5_zpbWQ\n",
    "[cpu model baidu link]: https://pan.baidu.com/s/1ZpxY4Ld-G-wfemc6OD8GEg\n",
    "[coco_address]: http://cocodataset.org/#download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Video Demo\n",
    "Demo1\n",
    "[Youtube][ytb_link1] , [Youku][yk_link1]\n",
    "Demo2\n",
    "[Youtube][ytb_link2] , [Youku][yk_link2]\n",
    "[ytb_link1]:https://youtu.be/GZiUX4gczOc\n",
    "[yk_link1]:https://v.youku.com/v_show/id_XMzcxMTQ0OTI3Ng==.html?spm=a2hzp.8244740.0.0\n",
    "[ytb_link2]:https://youtu.be/C61NDUsA78k\n",
    "[yk_link2]:https://v.youku.com/v_show/id_XMzcxMTY4MTUzMg==.html?spm=a2h3j.8428770.3416059.1\n",
    "\n",
    "### Detection Example\n",
    "<img src='data/city_detected.jpg',width=1200, height=800>\n",
    "<img src='data/dinner_detected.jpg',width=1200, height=800>\n",
    "<img src='data/football_detected.jpg',width=1200, height=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The diffrence between this repo and the original [YOLOv3][paperlink]:\n",
    "[paperlink]: https://pjreddie.com/media/files/papers/YOLOv3.pdf\n",
    "1. Using Resnet50 as detection backbone instead of Darknet53.\n",
    "2. Switch the individual binary classifier with softmax cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T20:07:55.469126Z",
     "start_time": "2018-07-05T20:07:55.466253Z"
    }
   },
   "source": [
    "### Things that have been done:\n",
    "1. Full pytorch and numpy implementation of YOLOv3 training and detection\n",
    "2. Pytorch 0.4 codes\n",
    "2. Multi-Scale Training mentioned in the paper\n",
    "-> so far as I noticed, this one is not implemented by a lot of posts about yolo out there.\n",
    "5. lots of data augmentation,thanks to [imgaug][imgaug link]\n",
    "3. training in coco2017 dataset \n",
    "[imgaug link]:https://github.com/aleju/imgaug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use\n",
    "First, clone this repo by input:\n",
    "```\n",
    "git clone https://github.com/TreB1eN/Yolov3-in-Pytorch.git\n",
    "```\n",
    "\n",
    "#### Detection:\n",
    "1. Secondly, download the trained model from cloud drive into data/model folder\n",
    "\n",
    "    - Google Drive:\n",
    "        - [Cuda Model download][cuda model google link]:\n",
    "        - [CPU Model download][cpu model google link]:\n",
    "\n",
    "    - Baidu Netdisk:\n",
    "        - [Cuda Model download][cuda model baidu link]:\n",
    "        - [CPU Model download][cpu model baidu link]:\n",
    "\n",
    "2. For detection in single image, please run\n",
    "```\n",
    "python detect_on_image.py -f input_image_path -o output_image_path -l detection_level\n",
    "```\n",
    "3. For detection in video, please run\n",
    "```\n",
    "python detect_on_video.py -f input_video_path -o output_video_path -l detection_level\n",
    "```\n",
    "4. For detection in camera, please run\n",
    "```\n",
    "python detect_on_camera.py -l detection_level\n",
    "```\n",
    "- - -\n",
    "#### Training:\n",
    "1. download train2017.zip, val2017.zip and annotations_trainval2017.zip from [coco website][coco_address] to data/coco2017\n",
    "2. ```\n",
    "    unzip data/coco2017/train2017.zip\n",
    "    unzip data/coco2017/val2017.zip\n",
    "    unzip data/coco2017/annotations_trainval2017.zip\n",
    "    ```\n",
    "3. run\n",
    "    ```\n",
    "    python train.py\n",
    "    ```\n",
    "    Details and parameters are in the codes\n",
    "\n",
    "[cuda model google link]: https://drive.google.com/open?id=1VuA2SIUYat6bE6-8hvdGLCy1sDrmwK7z\n",
    "[cpu model google link]: https://drive.google.com/open?id=1xN-8gRId8JfW0dgotBtueOUqCKZfj0UF\n",
    "[cuda model baidu link]: https://pan.baidu.com/s/1H0gBY_CsRXmyxaV5_zpbWQ\n",
    "[cpu model baidu link]: https://pan.baidu.com/s/1ZpxY4Ld-G-wfemc6OD8GEg\n",
    "[coco_address]: http://cocodataset.org/#download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo List:\n",
    "* Hyperparameters Tuning\n",
    "* trained with original Darknet53\n",
    "* try Binary Classifier instead of Softmax as discussed in the paper\n",
    "---\n",
    "I dont't have much computing resource, PRs are welcomed !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Demo\n",
    "Demo1\n",
    "[Youtube][ytb_link1] , [Youku][yk_link1]\n",
    "Demo2\n",
    "[Youtube][ytb_link2] , [Youku][yk_link2]\n",
    "[ytb_link1]:https://youtu.be/GZiUX4gczOc\n",
    "[yk_link1]:https://v.youku.com/v_show/id_XMzcxMTQ0OTI3Ng==.html?spm=a2hzp.8244740.0.0\n",
    "[ytb_link2]:https://youtu.be/C61NDUsA78k\n",
    "[yk_link2]:https://v.youku.com/v_show/id_XMzcxMTY4MTUzMg==.html?spm=a2h3j.8428770.3416059.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T08:52:49.808273Z",
     "start_time": "2018-07-08T08:52:49.479572Z"
    }
   },
   "source": [
    "### Detection Example\n",
    "<img src='data/city_detected.jpg',width=1200, height=800>\n",
    "<img src='data/dinner_detected.jpg',width=1200, height=800>\n",
    "<img src='data/football_detected.jpg',width=1200, height=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOLOv3: An Incremental Improvement\n",
    "- [original Paper][paper]\n",
    "- [original Implementation][imple]\n",
    "- [website][web]\n",
    "This repo is also inspired by [marvis/pytorch-yolo2][v2] and [qqwweee/keras-yolo3][keras]\n",
    "[imple]: https://github.com/pjreddie/darknet\n",
    "[paper]: https://arxiv.org/abs/1804.02767\n",
    "[web]: https://pjreddie.com/darknet/yolo/?utm_source=next.36kr.com\n",
    "[v2]: https://github.com/marvis/pytorch-yolo2\n",
    "[keras]: https://github.com/qqwweee/keras-yolo3"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
