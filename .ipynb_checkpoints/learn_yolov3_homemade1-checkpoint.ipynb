{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as trans\n",
    "\n",
    "from pathlib import Path\n",
    "from models.yolo_body_res50 import Yolo_body\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.vis_utils import *\n",
    "from utils.box_utils import *\n",
    "from utils.dataset_tools import *\n",
    "from utils.utils import *\n",
    "from models.Yolo_head import Yolo_loss\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = edict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.coco_anchors = [[10,13],[16,30],[33,23],[30,61],[62,45],[59,119],[116,90],[156,198],[373,326]]\n",
    "conf.train_path = Path('/home/f/learning/Dataset/coco2017/train2017/')\n",
    "conf.train_anno_path = Path('/home/f/learning/Dataset/coco2017/annotations/instances_train2017.json')\n",
    "conf.val_path = Path('/home/f/learning/Dataset/coco2017/val2017/')\n",
    "conf.val_anno_path = Path('/home/f/learning/Dataset/coco2017/annotations/instances_val2017.json')\n",
    "conf.log_path = Path('/home/f/learning/yolo/log')\n",
    "conf.model_path = Path('/home/f/learning/yolo/model')\n",
    "conf.save_path = Path('/home/f/learning/yolo/save')\n",
    "\n",
    "conf.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=8.14s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=8.39s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CocoDetection(conf.train_path,conf.train_anno_path)\n",
    "coco_class_2_id,coco_id_2_class = get_coco_class_name_map(conf.train_anno_path)\n",
    "conf.class_num = len(coco_id_2_class)\n",
    "\n",
    "id_2_correct_id = {}\n",
    "correct_id_2_id = {}\n",
    "id_2_correct_id = dict(zip(coco_id_2_class.keys(),range(80)))\n",
    "correct_id_2_id = dict(zip(range(80),coco_id_2_class.keys()))\n",
    "\n",
    "correct_id_2_class = {}\n",
    "class_2_correct_id = {}\n",
    "for k,v in coco_id_2_class.items():\n",
    "    correct_id_2_class[id_2_correct_id[k]] = v\n",
    "    class_2_correct_id[v] = id_2_correct_id[k]\n",
    "\n",
    "train_dataset.maps = [id_2_correct_id,correct_id_2_id,correct_id_2_class,class_2_correct_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2_correct_id = {}\n",
    "correct_id_2_id = {}\n",
    "id_2_correct_id = dict(zip(coco_id_2_class.keys(),range(80)))\n",
    "correct_id_2_id = dict(zip(range(80),coco_id_2_class.keys()))\n",
    "\n",
    "correct_id_2_class = {}\n",
    "class_2_correct_id = {}\n",
    "for k,v in coco_id_2_class.items():\n",
    "    correct_id_2_class[id_2_correct_id[k]] = v\n",
    "    class_2_correct_id[v] = id_2_correct_id[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.maps = [id_2_correct_id,correct_id_2_id,correct_id_2_class,class_2_correct_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "val_dataset = datasets.CocoDetection(conf.val_path,conf.val_anno_path)\n",
    "val_dataset.maps = train_dataset.maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolo_body(conf.class_num)\n",
    "model.to(conf.device)\n",
    "conf.mean = model.res50_pyramid.model.mean\n",
    "conf.std = model.res50_pyramid.model.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.batch_size = 4\n",
    "conf.input_size = [416,416]\n",
    "conf.transform = trans.Compose([\n",
    "    trans.Resize(conf.input_size),\n",
    "    trans.ToTensor(),\n",
    "    trans.Normalize(conf.mean,conf.std)\n",
    "])\n",
    "\n",
    "conf.mse_loss = nn.MSELoss(size_average=False)\n",
    "conf.bce_loss = nn.BCEWithLogitsLoss\n",
    "conf.evaluate_iou_threshold = 0.5\n",
    "conf.predict_confidence_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_bbox_class(trans.ToPILImage()(de_preprocess(imgs[1],conf.mean,conf.std)),labels[1],bboxes[1],train_dataset.maps[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Coco_loader(conf,train_dataset,conf.transform,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.board_loss_every = len(train_loader)//100\n",
    "conf.evaluate_every = len(train_loader)//10\n",
    "conf.board_pred_image_every = len(train_loader)//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = Coco_loader(conf,val_dataset,conf.transform,batch_size=4,hflip=False,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_loss_small = Yolo_loss(conf,conf.coco_anchors[:3],13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_loss_medium = Yolo_loss(conf,conf.coco_anchors[3:6],26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yolo_loss_large = Yolo_loss(conf,conf.coco_anchors[6:9],52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_anchors = torch.tensor(conf.coco_anchors,dtype=torch.float32)\n",
    "loss_layers = [yolo_loss_small,yolo_loss_medium,yolo_loss_large]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(conf.log_path/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,labels_group,bboxes_group = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "for i,label in enumerate(labels_group):\n",
    "    labels_group[i] = label.to(conf.device)\n",
    "    print(labels_group[i].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_group[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = Yolo(model,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1250 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "val_loss,pseudo_recall,\\\n",
    "    running_loss_x,\\\n",
    "    running_loss_y,\\\n",
    "    running_loss_w,\\\n",
    "    running_loss_h,\\\n",
    "    running_loss_conf,\\\n",
    "    running_loss_cls,\\\n",
    "    precision,recall,f1,cls_acc   = yolo.evaluate(conf,True,20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16093.800573730468,\n",
       " 0.33986928104575165,\n",
       " 1.1659590720693813,\n",
       " 1.0983740272255091,\n",
       " 2.829422786424402,\n",
       " 5.233464184124022,\n",
       " 14441.094653320313,\n",
       " 1420.1479427337647,\n",
       " 0.05555555555555555,\n",
       " 0.011254019292604502,\n",
       " 0.018716574738626063,\n",
       " 0.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss,\\\n",
    "    pseudo_recall,\\\n",
    "    running_loss_x,\\\n",
    "    running_loss_y,\\\n",
    "    running_loss_w,\\\n",
    "    running_loss_h,\\\n",
    "    running_loss_conf,\\\n",
    "    running_loss_cls,\\\n",
    "    precision,recall,f1,cls_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo(object):\n",
    "    def __init__(self,model=None,train_loader=None,val_loader=None,writer=None,optimizer=None,step=0,seen=0):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.writer = writer\n",
    "        self.step = step\n",
    "        self.seen = seen\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def predict(self,img,conf,threshold,only_objectness=True,return_img=False):\n",
    "        self.model.eval()\n",
    "        confidences_predicted = []\n",
    "        bboxes_predicted = []\n",
    "        classes_predicted = []\n",
    "        with torch.no_grad():\n",
    "            img.to(conf.device)\n",
    "            y1_13x13,y2_26x26,y3_52x52 = model(img.unsqueeze(0))\n",
    "            for output,feature_size,scale,anchors in [(y1_13x13,13,32.,conf.coco_anchors[:3]),\n",
    "                                                      (y2_26x26,26,16.,conf.coco_anchors[3:6]),\n",
    "                                                      (y3_52x52,52,8.,conf.coco_anchors[6:9])]:\n",
    "                anchors = torch.tensor(anchors,dtype=torch.float32,device=conf.device)\n",
    "                output = output.view(1, 3, (5+conf.class_num), feature_size, feature_size) # [32, 5, 85, 13, 13]\n",
    "                x = F.sigmoid(output[:,:,0,:,:])\n",
    "                y = F.sigmoid(output[:,:,1,:,:])\n",
    "                w = output[:,:,2,:,:]\n",
    "                h = output[:,:,3,:,:]\n",
    "                confidence = torch.sigmoid(output[:,:,4,:,:])[0]\n",
    "                cls = output[:,:,5:,:,:]\n",
    "                cls = cls.view(3,\n",
    "                               conf.class_num,\n",
    "                               feature_size*feature_size).transpose(1,2).contiguous().view(1,\n",
    "                                                                                           3,\n",
    "                                                                                           feature_size,\n",
    "                                                                                           feature_size,\n",
    "                                                                                           conf.class_num)\n",
    "                cls = torch.sigmoid(cls)[0]\n",
    "                shift_x,shift_y = enumerate_shifted_anchor(1,feature_size,feature_size)\n",
    "                shift_x,shift_y = shift_x.to(conf.device),shift_y.to(conf.device)\n",
    "                x_refine = (x + shift_x).unsqueeze(-1) \n",
    "                #refine means map x,y to each square in the 13*13 or 26*26 or 52*52 grid\n",
    "                y_refine = (y + shift_y).unsqueeze(-1)\n",
    "                w_refine = (torch.exp(w) * anchors[:,0].view(1,3,1,1)).unsqueeze(-1)\n",
    "                h_refine = (torch.exp(h) * anchors[:,1].view(1,3,1,1)).unsqueeze(-1)\n",
    "                pred_bbox = torch.cat([x_refine,y_refine,w_refine,h_refine],dim=-1)[0] * scale\n",
    "                max_cls_conf,class_predicted = torch.max(cls,dim=3)\n",
    "                if only_objectness:\n",
    "                    final_conf = confidence\n",
    "                    mask = final_conf > threshold\n",
    "                else:\n",
    "                    final_conf = confidence*max_cls_conf\n",
    "                    mask = final_conf > threshold\n",
    "                bbox_predicted = pred_bbox[mask]\n",
    "                class_predicted = class_predicted[mask]\n",
    "                confidence_predicted = final_conf[mask]\n",
    "                bboxes_predicted.append(bbox_predicted)\n",
    "                classes_predicted.append(class_predicted)\n",
    "                confidences_predicted.append(confidence_predicted)\n",
    "                bboxes = torch.cat(bboxes_predicted)\n",
    "                classes = torch.cat(classes_predicted)\n",
    "                confidences = torch.cat(confidences_predicted)\n",
    "                picked_boxes = non_max_suppression(bboxes.detach().clone().cpu().numpy(),\n",
    "                                                   confidences.detach().clone().cpu().numpy(),\n",
    "                                                   threshold)\n",
    "        self.model.train()\n",
    "        if return_img:\n",
    "            return trans.ToTensor()((draw_bbox_class(trans.ToPILImage()(de_preprocess(img,conf.mean,conf.std)),\n",
    "                                                      classes[picked_boxes],\n",
    "                                                      bboxes[picked_boxes],\n",
    "                                                      self.train_loader.dataset.maps[2])))\n",
    "        else:\n",
    "            return bboxes[picked_boxes],classes[picked_boxes],confidences[picked_boxes]\n",
    "    \n",
    "    def evaluate(self,conf,verbose=False,value_batches=20,img_batches=5):\n",
    "        self.model.eval()\n",
    "        if verbose:\n",
    "            loader = tqdm(iter(self.val_loader))\n",
    "        else:\n",
    "            loader = iter(self.val_loader)\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_nGT = 0.\n",
    "        running_nCorrect = 0.\n",
    "        running_loss_x = 0.\n",
    "        running_loss_y = 0.\n",
    "        running_loss_w = 0.\n",
    "        running_loss_h = 0.\n",
    "        running_loss_conf = 0.\n",
    "        running_loss_cls = 0.\n",
    "        n_correct = 0\n",
    "        n_gt = 0\n",
    "        n_pred = 0\n",
    "        cls_correct_num = 0\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            batch_count = 0\n",
    "            \n",
    "            for imgs,labels_group,bboxes_group in iter(val_loader):\n",
    "                \n",
    "                if batch_count < value_batches:\n",
    "                    imgs = imgs.to(conf.device)\n",
    "                    \n",
    "                    for i,label in enumerate(labels_group):\n",
    "                        labels_group[i] = label.to(conf.device)\n",
    "                    for i,bboxes in enumerate(bboxes_group):\n",
    "                        bboxes_group[i] = bboxes.to(conf.device)\n",
    "\n",
    "                    y1_13x13,y2_26x26,y3_52x52 = model(imgs)\n",
    "                    \n",
    "                    labels_group_small,labels_group_medium,labels_group_large,\\\n",
    "                    bboxes_group_small,bboxes_group_medium,bboxes_group_large,\\\n",
    "                    best_anchors_idx_group_small,\\\n",
    "                    best_anchors_idx_group_medium,\\\n",
    "                    best_anchors_idx_group_large = arrange_bbox_label(conf.device,conf.coco_anchors,labels_group,bboxes_group)\n",
    "\n",
    "                    large_feature,large_bboxes,\\\n",
    "                    large_labels,\\\n",
    "                    large_anchors_idx = prepare_loss_input(conf.device,y3_52x52,\n",
    "                                                           labels_group_large,\n",
    "                                                           bboxes_group_large,\n",
    "                                                           best_anchors_idx_group_large)\n",
    "\n",
    "                    medium_feature,\\\n",
    "                    medium_bboxes,\\\n",
    "                    medium_labels,\\\n",
    "                    medium_anchors_idx = prepare_loss_input(conf.device,y2_26x26,\n",
    "                                                            labels_group_medium,\n",
    "                                                            bboxes_group_medium,\n",
    "                                                            best_anchors_idx_group_medium)\n",
    "\n",
    "                    small_feature,\\\n",
    "                    small_bboxes,\\\n",
    "                    small_labels,\\\n",
    "                    small_anchors_idx = prepare_loss_input(conf.device,y1_13x13,\n",
    "                                                           labels_group_small,\n",
    "                                                           bboxes_group_small,\n",
    "                                                           best_anchors_idx_group_small)\n",
    "\n",
    "                    if len(large_feature) != 0:\n",
    "                        loss_large,nGT_large,nCorrect_large,\\\n",
    "                        loss_x_large,loss_y_large,loss_w_large,loss_h_large,\\\n",
    "                        loss_conf_large,loss_cls_large = yolo_loss_large(large_feature,\n",
    "                                                                         large_bboxes,\n",
    "                                                                         large_labels,\n",
    "                                                                         large_anchors_idx,\n",
    "                                                                         warm_up=False)\n",
    "                        running_loss += loss_large.item()\n",
    "                        running_nGT += nGT_large \n",
    "                        running_nCorrect += nCorrect_large\n",
    "                        running_loss_x += loss_x_large\n",
    "                        running_loss_y += loss_y_large\n",
    "                        running_loss_w += loss_w_large\n",
    "                        running_loss_h += loss_h_large\n",
    "                        running_loss_conf += loss_conf_large\n",
    "                        running_loss_cls += loss_cls_large\n",
    "\n",
    "                    if len(medium_feature) != 0:\n",
    "                        loss_medium,nGT_medium,nCorrect_medium,\\\n",
    "                        loss_x_medium,loss_y_medium,loss_w_medium,loss_h_medium,\\\n",
    "                        loss_conf_medium,loss_cls_medium = yolo_loss_medium(medium_feature,\n",
    "                                                                            medium_bboxes,\n",
    "                                                                            medium_labels,\n",
    "                                                                            medium_anchors_idx,\n",
    "                                                                            warm_up=False)\n",
    "                        running_loss += loss_medium.item()\n",
    "                        running_nGT += nGT_medium \n",
    "                        running_nCorrect += nCorrect_medium\n",
    "                        running_loss_x += loss_x_medium\n",
    "                        running_loss_y += loss_y_medium\n",
    "                        running_loss_w += loss_w_medium\n",
    "                        running_loss_h += loss_h_medium\n",
    "                        running_loss_conf += loss_conf_medium\n",
    "                        running_loss_cls += loss_cls_medium\n",
    "\n",
    "                    if len(small_feature) != 0:\n",
    "                        loss_small,nGT_small,nCorrect_small,\\\n",
    "                        loss_x_small,loss_y_small,loss_w_small,loss_h_small,\\\n",
    "                        loss_conf_small,loss_cls_small = yolo_loss_small(small_feature,\n",
    "                                                                         small_bboxes,\n",
    "                                                                         small_labels,\n",
    "                                                                         small_anchors_idx,\n",
    "                                                                         warm_up=False)\n",
    "                        running_loss += loss_small.item()\n",
    "                        running_nGT += nGT_small \n",
    "                        running_nCorrect += nCorrect_small\n",
    "                        running_loss_x += loss_x_small\n",
    "                        running_loss_y += loss_y_small\n",
    "                        running_loss_w += loss_w_small\n",
    "                        running_loss_h += loss_h_small\n",
    "                        running_loss_conf += loss_conf_small\n",
    "                        running_loss_cls += loss_cls_small\n",
    "                        \n",
    "                if batch_count < img_batches:\n",
    "                    for j in range(len(imgs)):\n",
    "                        \n",
    "                        pred_bboxes,pred_classes,_ = yolo.predict(imgs[j],\n",
    "                                                                  conf,\n",
    "                                                                  conf.predict_confidence_threshold,\n",
    "                                                                  only_objectness=True,\n",
    "                                                                  return_img=False)\n",
    "                        ious = cal_ious(pred_bboxes,bboxes_group[j]).to(conf.device)\n",
    "                        max_matched_iou_gt,max_matched_box_idx_gt = torch.max(ious,dim=0)\n",
    "                        matched_mask = max_matched_iou_gt > conf.evaluate_iou_threshold\n",
    "                        matched_classes = pred_classes[max_matched_box_idx_gt][matched_mask]\n",
    "                        cls_correct_num += torch.sum(matched_classes == labels_group[j][matched_mask]).item()\n",
    "\n",
    "                        n_pred += len(pred_bboxes)\n",
    "                        n_gt += len(bboxes_group[j])\n",
    "                        n_correct += torch.sum(matched_mask).item()\n",
    "                \n",
    "                batch_count += 1\n",
    "\n",
    "                if batch_count >= max(value_batches,img_batches):\n",
    "                    break\n",
    "            \n",
    "        precision = n_correct/n_gt\n",
    "        recall = n_correct/n_pred\n",
    "        f1 = 2*precision*recall / (precision + recall + 1e-8)\n",
    "        cls_acc = cls_correct_num/n_gt\n",
    "        \n",
    "        self.model.train()\n",
    "            \n",
    "        return running_loss/value_batches,\\\n",
    "    running_nCorrect/running_nGT,\\\n",
    "    running_loss_x/value_batches,\\\n",
    "    running_loss_y/value_batches,\\\n",
    "    running_loss_w/value_batches,\\\n",
    "    running_loss_h/value_batches,\\\n",
    "    running_loss_conf/value_batches,\\\n",
    "    running_loss_cls/value_batches,\\\n",
    "    precision,recall,f1,cls_acc   \n",
    "\n",
    "    def train(self,conf,epochs=1,scheduler=True,patience=2,log=None):\n",
    "        stagnate = 0\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_nGT = 0.\n",
    "        running_nCorrect = 0.\n",
    "        running_loss_x = 0.\n",
    "        running_loss_y = 0.\n",
    "        running_loss_w = 0.\n",
    "        running_loss_h = 0.\n",
    "        running_loss_conf = 0.\n",
    "        running_loss_cls = 0.      \n",
    "                \n",
    "        for imgs,labels_group,bboxes_group in tqdm(iter(self.train_loader)):\n",
    "            \n",
    "            imgs = imgs.to(conf.device)\n",
    "            for i,label in enumerate(labels_group):\n",
    "                labels_group[i] = label.to(conf.device)\n",
    "            for i,bboxes in enumerate(bboxes_group):\n",
    "                bboxes_group[i] = bboxes.to(conf.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            y1_13x13,y2_26x26,y3_52x52 = model(imgs)\n",
    "            \n",
    "            labels_group_small,labels_group_medium,labels_group_large,\\\n",
    "            bboxes_group_small,bboxes_group_medium,bboxes_group_large,\\\n",
    "            best_anchors_idx_group_small,\\\n",
    "            best_anchors_idx_group_medium,\\\n",
    "            best_anchors_idx_group_large = arrange_bbox_label(conf.device,conf.coco_anchors,labels_group,bboxes_group)\n",
    "            \n",
    "            large_feature,large_bboxes,\\\n",
    "            large_labels,\\\n",
    "            large_anchors_idx = prepare_loss_input(conf.device,y3_52x52,labels_group_large,bboxes_group_large,best_anchors_idx_group_large)\n",
    "\n",
    "            medium_feature,\\\n",
    "            medium_bboxes,\\\n",
    "            medium_labels,\\\n",
    "            medium_anchors_idx = prepare_loss_input(conf.device,y2_26x26,labels_group_medium,bboxes_group_medium,best_anchors_idx_group_medium)\n",
    "\n",
    "            small_feature,\\\n",
    "            small_bboxes,\\\n",
    "            small_labels,\\\n",
    "            small_anchors_idx = prepare_loss_input(conf.device,y1_13x13,labels_group_small,bboxes_group_small,best_anchors_idx_group_small)\n",
    "            \n",
    "            warm_up = True if self.seen > 12800 else False\n",
    "            \n",
    "            if len(large_feature) != 0:\n",
    "                loss_large,nGT_large,nCorrect_large,\\\n",
    "                loss_x_large,loss_y_large,loss_w_large,loss_h_large,\\\n",
    "                loss_conf_large,loss_cls_large = yolo_loss_large(large_feature,\n",
    "                                                                 large_bboxes,\n",
    "                                                                 large_labels,\n",
    "                                                                 large_anchors_idx,\n",
    "                                                                 warm_up)\n",
    "                loss += loss_large\n",
    "                running_nGT += nGT_large \n",
    "                running_nCorrect += nCorrect_large\n",
    "                running_loss_x += loss_x_large\n",
    "                running_loss_y += loss_y_large\n",
    "                running_loss_w += loss_w_large\n",
    "                running_loss_h += loss_h_large\n",
    "                running_loss_conf += loss_conf_large\n",
    "                running_loss_cls += loss_cls_large\n",
    "                \n",
    "            if len(medium_feature) != 0:\n",
    "                loss_medium,nGT_medium,nCorrect_medium,\\\n",
    "                loss_x_medium,loss_y_medium,loss_w_medium,loss_h_medium,\\\n",
    "                loss_conf_medium,loss_cls_medium = yolo_loss_medium(medium_feature,\n",
    "                                                                    medium_bboxes,\n",
    "                                                                    medium_labels,\n",
    "                                                                    medium_anchors_idx,\n",
    "                                                                    warm_up)\n",
    "                loss += loss_medium\n",
    "                running_nGT += nGT_medium \n",
    "                running_nCorrect += nCorrect_medium\n",
    "                running_loss_x += loss_x_medium\n",
    "                running_loss_y += loss_y_medium\n",
    "                running_loss_w += loss_w_medium\n",
    "                running_loss_h += loss_h_medium\n",
    "                running_loss_conf += loss_conf_medium\n",
    "                running_loss_cls += loss_cls_medium\n",
    "                \n",
    "            if len(small_feature) != 0:\n",
    "                loss_small,nGT_small,nCorrect_small,\\\n",
    "                loss_x_small,loss_y_small,loss_w_small,loss_h_small,\\\n",
    "                loss_conf_small,loss_cls_small = yolo_loss_small(small_feature,\n",
    "                                                                 small_bboxes,\n",
    "                                                                 small_labels,\n",
    "                                                                 small_anchors_idx,\n",
    "                                                                 warm_up)\n",
    "                loss += loss_small\n",
    "                running_nGT += nGT_small \n",
    "                running_nCorrect += nCorrect_small\n",
    "                running_loss_x += loss_x_small\n",
    "                running_loss_y += loss_y_small\n",
    "                running_loss_w += loss_w_small\n",
    "                running_loss_h += loss_h_small\n",
    "                running_loss_conf += loss_conf_small\n",
    "                running_loss_cls += loss_cls_small\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.step += 1\n",
    "            \n",
    "            running_loss += loss.detach().item()\n",
    "            \n",
    "            if self.step % conf.board_loss_every == 0:\n",
    "                if warm_up:\n",
    "                    writer.add_scalar('loss_warm_up',running_loss/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('pseudo_recall_warm_up',running_nCorrect/running_nGT,self.step)\n",
    "                    writer.add_scalar('loss_x_warm_up',running_loss_x/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_y_warm_up',running_loss_y/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_w_warm_up',running_loss_w/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_h_warm_up',running_loss_h/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_conf_warm_up',running_loss_conf/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_cls_warm_up',running_loss_cls/conf.board_loss_every,self.step)\n",
    "                else:\n",
    "                    writer.add_scalar('loss',running_loss/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('pseudo_recall',running_nCorrect/running_nGT,self.step)\n",
    "                    writer.add_scalar('loss_x',running_loss_x/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_y',running_loss_y/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_w',running_loss_w/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_h',running_loss_h/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_conf',running_loss_conf/conf.board_loss_every,self.step)\n",
    "                    writer.add_scalar('loss_cls',running_loss_cls/conf.board_loss_every,self.step)\n",
    "                    \n",
    "                running_loss = 0.\n",
    "                running_nGT = 0.\n",
    "                running_nCorrect = 0.\n",
    "                running_loss_x = 0.\n",
    "                running_loss_y = 0.\n",
    "                running_loss_w = 0.\n",
    "                running_loss_h = 0.\n",
    "                running_loss_conf = 0.\n",
    "                running_loss_cls = 0.\n",
    "            \n",
    "            if self.step % conf.evaluate_every == 0:\n",
    "                val_loss,\\\n",
    "                pseudo_recall,\\\n",
    "                val_loss_x,\\\n",
    "                val_loss_y,\\\n",
    "                val_loss_w,\\\n",
    "                val_loss_h,\\\n",
    "                val_loss_conf,\\\n",
    "                val_loss_cls,\\\n",
    "                precision,recall,f1,cls_acc = self.evaluate(conf,100,50)\n",
    "                \n",
    "                writer.add_scalar('val_loss',val_loss,self.step)\n",
    "                writer.add_scalar('val_pseudo_recall',pseudo_recall,self.step)\n",
    "                writer.add_scalar('val_loss_x',val_loss_x,self.step)\n",
    "                writer.add_scalar('val_loss_y'val_loss_y,self.step)\n",
    "                writer.add_scalar('val_loss_w',val_loss_w,self.step)\n",
    "                writer.add_scalar('val_loss_h',val_loss_h,self.step)\n",
    "                writer.add_scalar('val_loss_conf',val_loss_conf,self.step)\n",
    "                writer.add_scalar('val_loss_cls',val_loss_cls,self.step)\n",
    "                writer.add_scalar('val_precision',precision,self.step)\n",
    "                writer.add_scalar('val_recall',recall,self.step)\n",
    "                writer.add_scalar('val_f1',f1,self.step)\n",
    "                writer.add_scalar('val_cls_acc',cls_acc,self.step)\n",
    "                \n",
    "            if self.step % conf.board_pred_image_every == 0:\n",
    "                for i in range(20):\n",
    "                    img,_,_ = self.val_loader.dataset[i]\n",
    "                    img_tensor = self.predict(img,\n",
    "                                              conf,\n",
    "                                              conf.predict_confidence_threshold,\n",
    "                                              only_objectness=True,\n",
    "                                              return_img=True)\n",
    "                    writer.add_image('pred_image_{}'.format(i),img_tensor,global_step=self.step)\n",
    "            \n",
    "            self.seen += len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,labels_group,bboxes_group = next(iter(train_loader))\n",
    "\n",
    "y1_13x13,y2_26x26,y3_52x52 = model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_group_small,labels_group_medium,labels_group_large,\\\n",
    "bboxes_group_small,bboxes_group_medium,bboxes_group_large,\\\n",
    "best_anchors_idx_group_small,\\\n",
    "best_anchors_idx_group_medium,\\\n",
    "best_anchors_idx_group_large = arrange_bbox_label(conf.coco_anchors,labels_group,bboxes_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_feature,large_bboxes,large_labels,large_anchors_idx = prepare_loss_input(y3_52x52,\n",
    "                                                                               labels_group_large,\n",
    "                                                                               bboxes_group_large,\n",
    "                                                                               best_anchors_idx_group_large)\n",
    "\n",
    "medium_feature,medium_bboxes,medium_labels,medium_anchors_idx = prepare_loss_input(y2_26x26,\n",
    "                                                                                   labels_group_medium,\n",
    "                                                                                   bboxes_group_medium,\n",
    "                                                                                   best_anchors_idx_group_medium)\n",
    "\n",
    "small_feature,small_bboxes,small_labels,small_anchors_idx = prepare_loss_input(y1_13x13,\n",
    "                                                                               labels_group_small,\n",
    "                                                                               bboxes_group_small,\n",
    "                                                                               best_anchors_idx_group_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(large_feature) != 0:\n",
    "    loss_large,nGT_large,nCorrect_large,\\\n",
    "    loss_x_large,loss_y_large,loss_w_large,loss_h_large,\\\n",
    "    loss_conf_large,loss_cls_large = yolo_loss_large(large_feature,\n",
    "                                                     large_bboxes,\n",
    "                                                     large_labels,\n",
    "                                                     large_anchors_idx,True)\n",
    "if len(medium_feature) != 0:\n",
    "    loss_medium,nGT_medium,nCorrect_medium,\\\n",
    "    loss_x_medium,loss_y_medium,loss_w_medium,loss_h_medium,\\\n",
    "    loss_conf_medium,loss_cls_medium = yolo_loss_medium(medium_feature,\n",
    "                                                     medium_bboxes,\n",
    "                                                     medium_labels,\n",
    "                                                     medium_anchors_idx,True)\n",
    "if len(small_feature) != 0:\n",
    "    loss_small,nGT_small,nCorrect_small,\\\n",
    "    loss_x_small,loss_y_small,loss_w_small,loss_h_small,\\\n",
    "    loss_conf_small,loss_cls_small = yolo_loss_small(small_feature,\n",
    "                                                     small_bboxes,\n",
    "                                                     small_labels,\n",
    "                                                     small_anchors_idx,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
