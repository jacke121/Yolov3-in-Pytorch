{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T09:47:19.277410Z",
     "start_time": "2018-07-02T09:47:19.096086Z"
    }
   },
   "outputs": [],
   "source": [
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T09:47:20.434697Z",
     "start_time": "2018-07-02T09:47:19.278694Z"
    }
   },
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms as trans\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "# np.seterr(all='raise')\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "# import torch.nn.functional as F\n",
    "from utils.vis_utils import *\n",
    "from utils.box_utils import *\n",
    "from utils.dataset_tools import *\n",
    "from utils.utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "from torch.utils.data import DataLoader\n",
    "from models.Yolo_model import Yolo_model, build_targets, yolo_loss\n",
    "from Yolo_learner_V2 import Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T09:47:32.075238Z",
     "start_time": "2018-07-02T09:47:20.436236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.48s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "conf = edict()\n",
    "\n",
    "conf.coco_anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],\n",
    "                     [59, 119], [116, 90], [156, 198], [373, 326]]\n",
    "conf.train_path = Path('/home/f/nvme/coco2017/train2017/')\n",
    "conf.train_anno_path = Path(\n",
    "    '/home/f/nvme/coco2017/annotations/instances_train2017.json')\n",
    "conf.val_path = Path('/home/f/nvme/coco2017/val2017/')\n",
    "conf.val_anno_path = Path(\n",
    "    '/home/f/nvme/coco2017/annotations/instances_val2017.json')\n",
    "conf.log_path = Path('/home/f/learning/yolo/log')\n",
    "conf.model_path = Path('/home/f/learning/yolo/model')\n",
    "conf.save_path = Path('/home/f/learning/yolo/save')\n",
    "conf.ids_path = 'data/ids.npy'\n",
    "\n",
    "conf.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "maps,correct_id_2_class = get_id_maps(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T09:47:44.828042Z",
     "start_time": "2018-07-02T09:47:32.077185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "conf.num_anchors = 3\n",
    "conf.batch_size = 16\n",
    "conf.resolutions = [224,288,352,416,480,544,608]\n",
    "conf.res_2_idx = edict({'ft':0, '224':1, '288':2, '352':3, '416':4, '480':5, '544':6, '608':7})\n",
    "conf.idx_2_res = edict()\n",
    "for k,v in conf.res_2_idx.items():\n",
    "    conf.idx_2_res[str(v)] = k\n",
    "conf.input_size = 416\n",
    "conf.scales = [32, 16, 8]\n",
    "\n",
    "conf.running_norm = 0.\n",
    "# conf.gdclip = 3000.\n",
    "conf.num_workers = 4\n",
    "conf.batch_size = 16\n",
    "conf.gdclip = None\n",
    "conf.coord_scale = 2.\n",
    "conf.noobject_scale = 0.5\n",
    "conf.object_scale = 5\n",
    "conf.class_scale = 5.\n",
    "conf.ignore_thresh = 0.5\n",
    "conf.evaluate_iou_threshold = 0.5\n",
    "conf.predict_confidence_threshold = 0.5\n",
    "conf.pred_nms_iou_threshold = 0.5\n",
    "conf.object_only = True\n",
    "conf.warm_up_img_num = 12800\n",
    "\n",
    "model = Yolo_model(conf)\n",
    "model.to(conf.device)\n",
    "conf.mean = model.res50_pyramid.model.mean\n",
    "conf.std = model.res50_pyramid.model.std\n",
    "\n",
    "conf.mse_loss = nn.MSELoss(size_average=False)\n",
    "conf.bce_loss = nn.BCEWithLogitsLoss(size_average=False)\n",
    "\n",
    "# conf.eva_batches = 5\n",
    "# conf.board_loss_every = 5\n",
    "# conf.evaluate_every = 5\n",
    "# conf.board_pred_image_every = 5\n",
    "# conf.save_every = 5\n",
    "\n",
    "train_ds = Coco_dataset(conf, conf.train_path, conf.train_anno_path, maps)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=conf.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=coco_collate_fn,\n",
    "    pin_memory=False,\n",
    "    num_workers=conf.num_workers)\n",
    "conf.eva_batches = 100\n",
    "conf.board_loss_every = len(train_loader) // 100\n",
    "conf.evaluate_every = len(train_loader) // 10\n",
    "conf.board_pred_image_every = len(train_loader) // 2\n",
    "conf.save_every = len(train_loader) // 2\n",
    "conf.board_grad_norm = len(train_loader) // 10\n",
    "val_dataset = datasets.CocoDetection(conf.val_path, conf.val_anno_path)\n",
    "val_dataset.maps = maps\n",
    "conf.transform_test = trans.Compose([\n",
    "    trans.Resize([conf.input_size, conf.input_size]),\n",
    "    trans.ToTensor(),\n",
    "    trans.Normalize(conf.mean, conf.std)\n",
    "])\n",
    "val_loader = Coco_loader(\n",
    "    conf,\n",
    "    val_dataset,\n",
    "    conf.transform_test,\n",
    "    batch_size=conf.batch_size,\n",
    "    hflip=False,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T09:47:44.848841Z",
     "start_time": "2018-07-02T09:47:44.829673Z"
    }
   },
   "outputs": [],
   "source": [
    "paras = [*model.parameters()][159:]\n",
    "\n",
    "optimizer = optim.SGD(paras,lr=1e-4,momentum=0.9,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T09:47:44.871102Z",
     "start_time": "2018-07-02T09:47:44.850202Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo = Yolo(conf,model,train_loader,val_loader,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T09:47:45.359212Z",
     "start_time": "2018-07-02T09:47:44.872417Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo.model.load_state_dict(\n",
    "    torch.load(\n",
    "        conf.model_path /\n",
    "        '2018-07-02-08-26_val_loss:195.18045036315917_model_seen:351483_step:22176_None.pth'\n",
    "    ))\n",
    "yolo.optimizer.load_state_dict(\n",
    "    torch.load(\n",
    "        conf.model_path /\n",
    "        '2018-07-02-08-26_val_loss:195.18045036315917_optimizer_seen:351483_step:22176_None.pth'\n",
    "    ))\n",
    "yolo.seen = 351483\n",
    "yolo.steps[0] = 22176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T09:48:29.830513Z",
     "start_time": "2018-07-02T09:47:45.360785Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ed9c2e606d4deebe73622166577351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7393), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/root/Notebooks/YOLOv3/utils/dataset_tools.py\", line 47, in __getitem__\n",
      "    mask_img = aff_tsfm_mask(mask_img)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/root/Notebooks/YOLOv3/utils/dataset_tools.py\", line 57, in __getitem__\n",
      "    (aff_tsfm_img(img)),torch.cat(bboxes),torch.tensor(category_ids,dtype=torch.long))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 283, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/root/Notebooks/YOLOv3/utils/augment.py\", line 59, in <lambda>\n",
      "    trans.Lambda(lambda x: imgaug_on_PIL(iaa_mask,x)),\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 283, in __call__\n",
      "    return self.lambd(img)\n",
      "  File \"/root/Notebooks/YOLOv3/utils/augment.py\", line 89, in imgaug_on_PIL\n",
      "    return Image.fromarray(iaa_ins.augment_image(np.asarray(img)))\n",
      "  File \"/root/Notebooks/YOLOv3/utils/augment.py\", line 54, in <lambda>\n",
      "    trans.Lambda(lambda x: imgaug_on_PIL(iaa_img,x)),\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2446, in fromarray\n",
      "    obj = obj.tobytes()\n",
      "  File \"/root/Notebooks/YOLOv3/utils/augment.py\", line 89, in imgaug_on_PIL\n",
      "    return Image.fromarray(iaa_ins.augment_image(np.asarray(img)))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\", line 257, in augment_image\n",
      "    return self.augment_images([image], hooks=hooks)[0]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\", line 365, in augment_images\n",
      "    hooks=hooks\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\", line 1421, in _augment_images\n",
      "    hooks=hooks\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\", line 365, in augment_images\n",
      "    hooks=hooks\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\", line 1668, in _augment_images\n",
      "    hooks=hooks\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/meta.py\", line 365, in augment_images\n",
      "    hooks=hooks\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/imgaug/augmenters/geometric.py\", line 995, in _augment_images\n",
      "    warped = cv2.warpPerspective(images[i], M, (max_width, max_height))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-bc7ef83bd3bc>\", line 1, in <module>\n",
      "    yolo.train(conf,2)\n",
      "  File \"/root/Notebooks/YOLOv3/Yolo_learner_V2.py\", line 283, in train\n",
      "    self.model.head.anchors_group, warm_up)\n",
      "  File \"/root/Notebooks/YOLOv3/models/Yolo_model.py\", line 183, in build_targets\n",
      "    targets[l][b,best_anchor_idx_inGroup,gt_ij[1],gt_ij[0],1] = true_xy[1]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1480, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1438, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 386, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 420, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 169, in islink\n",
      "    st = os.lstat(path)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 7497) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "yolo.train(conf,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "writer_544 = SummaryWriter(conf.log_path/'size_544')\n",
    "writer_480 = SummaryWriter(conf.log_path/'size_480')\n",
    "writer_416 = SummaryWriter(conf.log_path/'size_416')\n",
    "writer_352 = SummaryWriter(conf.log_path/'size_352')\n",
    "writer_288 = SummaryWriter(conf.log_path/'size_288')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "yolo.update_size(conf,writer_416)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
